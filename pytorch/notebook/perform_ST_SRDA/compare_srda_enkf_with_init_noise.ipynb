{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41016fb-f196-4327-938c-d16ca860dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109dfe1-4752-4aba-9927-412cc9bac8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import DEBUG, INFO, WARNING, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff3d0c-158a-4e55-8ad1-dcb95dc880f3",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a862ea7-9414-4e0d-b678-c5792d0e96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from cfd_model.interpolator.torch_interpolator import (\n",
    "    interpolate,\n",
    "    interpolate_time_series,\n",
    ")\n",
    "from IPython.display import display\n",
    "from src.ssim import SSIM\n",
    "from src.utils import read_pickle, set_seeds\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c0e21-af29-45ea-ae12-386de09d38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic\n",
    "set_seeds(42, use_deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9a573-5ea5-4e0e-b026-61f522908f60",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1324e8-fd38-4c97-8dfe-58b5351f7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = str((pathlib.Path(os.environ[\"PYTHONPATH\"]) / \"..\").resolve())\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3512a9-d0a2-4d47-8a27-046d5db5d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:1\"\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU. CPU is used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08f7a7-cb6c-46c6-9e5a-d8c3997ddded",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DATA_DIR = \"./data\"\n",
    "os.makedirs(TMP_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70fe06-9eb2-4a2c-aa38-6c7c437d4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DATA_DIR = \"./csv\"\n",
    "os.makedirs(CSV_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9dae1-f4e3-481f-a258-063f999e0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG_DIR = f\"{ROOT_DIR}/doc/james_1st_rev/fig\"\n",
    "# os.makedirs(FIG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c7881-319a-42a1-ba72-a6201c207ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = f\"{ROOT_DIR}/pytorch/config/paper_experiment_06\"\n",
    "CONFIG_PATHS = sorted(glob.glob(f\"{CONFIG_DIR}/*.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e73549-551e-4c66-8170-401e223a94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENKF_ROOT_DIR = f\"{ROOT_DIR}/pytorch/notebook/paper_experiment_02/data/EnKF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6578f8d-1400-4116-8a8b-34dfd811e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSIMILATION_PERIOD = 4\n",
    "FORECAST_SPAN = 4\n",
    "START_TIME_INDEX = 0\n",
    "MAX_TIME_INDEX_FOR_INTEGRATION = 96\n",
    "\n",
    "LR_NX = 32\n",
    "LR_NY = 17\n",
    "LR_DT = 5e-4\n",
    "LR_NT = 500\n",
    "\n",
    "HR_NX = 128\n",
    "HR_NY = 65\n",
    "\n",
    "Y0_MEAN = np.pi / 2.0\n",
    "SIGMA_MEAN = 0.4\n",
    "TAU0_MEAN = 0.3\n",
    "\n",
    "BETA = 0.1\n",
    "COEFF_LINEAR_DRAG = 1e-2\n",
    "ORDER_DIFFUSION = 2\n",
    "HR_COEFF_DIFFUSION = 1e-5\n",
    "LR_COEFF_DIFFUSION = 5e-5\n",
    "\n",
    "DT = LR_DT * LR_NT\n",
    "T0 = START_TIME_INDEX * LR_DT * LR_NT\n",
    "\n",
    "N_ENS_PER_CHUNK = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b46390-586b-47bd-bf06-ac6a29862479",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = OrderedDict()\n",
    "\n",
    "for config_path in CONFIG_PATHS:\n",
    "    with open(config_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    config_name = os.path.basename(config_path).split(\".\")[0]\n",
    "    assert config_name not in CONFIGS\n",
    "\n",
    "    experiment_name = config_path.split(\"/\")[-2]\n",
    "    _dir = f\"{ROOT_DIR}/data/pytorch/DL_results/{experiment_name}/{config_name}\"\n",
    "\n",
    "    CONFIGS[config_name] = {\n",
    "        \"config\": config,\n",
    "        \"model_name\": config[\"model\"][\"model_name\"],\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"weight_path\": f\"{_dir}/weights.pth\",\n",
    "        \"learning_history_path\": f\"{_dir}/learning_history.csv\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af552217-c54d-43b1-924d-f8eeca749efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_GRID_RATIO = {\n",
    "    0: 0.0,\n",
    "    4: 0.06250000093132257,\n",
    "    5: 0.03999999910593033,\n",
    "    6: 0.027777777363856632,\n",
    "    7: 0.02040816326530612,\n",
    "    8: 0.015625000116415322,\n",
    "    9: 0.012345679127323775,\n",
    "    10: 0.010000000149011612,\n",
    "    11: 0.008264463206306716,\n",
    "    12: 0.006944444625534945,\n",
    "    13: 0.005917159876284691,\n",
    "    14: 0.005102040977882487,\n",
    "    15: 0.004444444572759999,\n",
    "    16: 0.003906250014551915,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6431ca-0f83-4079-9f33-381617617153",
   "metadata": {},
   "source": [
    "# Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b87a9-44b8-4ffa-a7f7-497390bcc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    dict_data: dict,\n",
    "    t: float,\n",
    "    obs: np.ndarray,\n",
    "    figsize: list = [20, 2],\n",
    "    write_out: bool = False,\n",
    "    ttl_header: str = \"\",\n",
    "    fig_file_name: str = \"\",\n",
    "    use_hr_space: bool = True,\n",
    "    vmin_omega: float = -9,\n",
    "    vmax_omega: float = 9,\n",
    "):\n",
    "\n",
    "    xs = np.linspace(0, 2 * np.pi, num=HR_NX, endpoint=False)\n",
    "    ys = np.linspace(0, np.pi, num=HR_NY, endpoint=True)\n",
    "    hr_x, hr_y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "    xs = np.linspace(0, 2 * np.pi, num=LR_NX, endpoint=False)\n",
    "    ys = np.linspace(0, np.pi, num=LR_NY, endpoint=True)\n",
    "    lr_x, lr_y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    fig, axes = plt.subplots(\n",
    "        1, len(dict_data), figsize=figsize, sharex=True, sharey=False\n",
    "    )\n",
    "\n",
    "    gt = None\n",
    "    for ax, (label, data) in zip(axes, dict_data.items()):\n",
    "        if \"LR\" in label:\n",
    "            if use_hr_space:\n",
    "                data = interpolate(\n",
    "                    torch.from_numpy(data[None, :]), nx=HR_NX, ny=HR_NY, mode=\"nearest\"\n",
    "                ).numpy()\n",
    "        else:\n",
    "            if not use_hr_space:\n",
    "                data = interpolate(\n",
    "                    torch.from_numpy(data[None, :]), nx=LR_NX, ny=LR_NY\n",
    "                ).numpy()\n",
    "\n",
    "        if use_hr_space:\n",
    "            x, y = hr_x, hr_y\n",
    "        else:\n",
    "            x, y = lr_x, lr_y\n",
    "\n",
    "        d = np.squeeze(data)\n",
    "        if label == \"HR\":\n",
    "            gt = d\n",
    "            ttl = \"HR Ground Truth\"\n",
    "        else:\n",
    "            maer = np.mean(np.abs(gt - d)) / np.mean(np.abs(gt))\n",
    "            ttl = label\n",
    "            ttl = f\"{label}\\nMAER={maer:.2f}\"\n",
    "\n",
    "        if use_hr_space:\n",
    "            assert d.shape == (HR_NX, HR_NY)\n",
    "        else:\n",
    "            assert d.shape == (LR_NX, LR_NY)\n",
    "\n",
    "        cnts = ax.pcolormesh(\n",
    "            x, y, d, cmap=\"twilight_shifted\", vmin=vmin_omega, vmax=vmax_omega\n",
    "        )\n",
    "        ax.set_title(ttl)\n",
    "\n",
    "        fig.colorbar(\n",
    "            cnts,\n",
    "            ax=ax,\n",
    "            ticks=[vmin_omega, vmin_omega / 2, 0, vmax_omega / 2, vmax_omega],\n",
    "            extend=\"both\",\n",
    "        )\n",
    "\n",
    "        ax.set_xlim([0, 2 * np.pi])\n",
    "        ax.set_ylim([0, np.pi])\n",
    "\n",
    "        if label == \"HR\" and use_hr_space:\n",
    "            obs = np.squeeze(obs).flatten()\n",
    "            obs_x = x.flatten()[~np.isnan(obs)]\n",
    "            obs_y = y.flatten()[~np.isnan(obs)]\n",
    "            ax.scatter(obs_x, obs_y, marker=\".\", s=1, c=\"k\")\n",
    "\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "    plt.suptitle(f\"{ttl_header}Time = {t}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # if write_out:\n",
    "    #     fig.savefig(f\"{FIG_DIR}/{fig_file_name}.jpg\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def read_all_tmp_files(config_name):\n",
    "    npz_file_path = f\"{TMP_DATA_DIR}/{config_name}_with_init_noise.npz\"\n",
    "    data = np.load(npz_file_path)\n",
    "\n",
    "    return data[\"sr_frcst\"], data[\"lr_omega\"], data[\"hr_omega\"], data[\"hr_obsrv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e080a44-21d4-46f1-ab69-995f127596aa",
   "metadata": {},
   "source": [
    "# Vorticity snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf622624-b108-4cdb-a45e-f5fe79a29f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_grid_interval = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d132773-16cc-45a5-9a98-286e5c917c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_config_name = (\n",
    "    f\"lt4og{obs_grid_interval:02}_on1e-01_ep1000_lr1e-04_scT_bT_muT_a02_b02_sd832180\"\n",
    ")\n",
    "\n",
    "(\n",
    "    all_sr_forecast,\n",
    "    all_lr_omega,\n",
    "    all_hr_omega,\n",
    "    all_hr_obsrv,\n",
    ") = read_all_tmp_files(target_config_name)\n",
    "\n",
    "enkf_dir = f\"{ENKF_ROOT_DIR}/{target_config_name}_with_init_noise\"\n",
    "assert os.path.exists(enkf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb094cc-a716-4389-9f94-132930036a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_ensemble in [185]:\n",
    "\n",
    "    enkf_lr = np.load(f\"{enkf_dir}/ens_all_lr_{i_ensemble:04}_with_init_noise.npy\")\n",
    "    enkf_lr = np.mean(enkf_lr, axis=0)  # ensemble mean\n",
    "    assert enkf_lr.shape == (MAX_TIME_INDEX_FOR_INTEGRATION, 32, 17)\n",
    "\n",
    "    enkf_hr = read_pickle(\n",
    "        f\"{enkf_dir}/ens_mean_hr_{i_ensemble:04}_with_init_noise.pickle\"\n",
    "    )\n",
    "\n",
    "    for i_cycle in [28, 56, 92]:\n",
    "        t = (i_cycle + START_TIME_INDEX) * DT\n",
    "\n",
    "        dict_data = {\n",
    "            \"HR\": all_hr_omega[i_ensemble, i_cycle],\n",
    "            \"LR\": all_lr_omega[i_ensemble, i_cycle],\n",
    "            \"EnKF(LR)\": enkf_lr[i_cycle],\n",
    "            \"EnKF(HR)\": enkf_hr[i_cycle],\n",
    "            \"SRDA\": all_sr_forecast[i_ensemble, i_cycle],\n",
    "        }\n",
    "\n",
    "        plot(\n",
    "            dict_data,\n",
    "            t,\n",
    "            obs=all_hr_obsrv[i_ensemble, i_cycle],\n",
    "            figsize=[24, 4.0],\n",
    "            ttl_header=f\"i_ens = {i_ensemble}, \",\n",
    "            fig_file_name=f\"snapshot_srda_vs_enkf_t{int(t):03}\",\n",
    "            write_out=True,\n",
    "            use_hr_space=False,\n",
    "            vmin_omega=-10,\n",
    "            vmax_omega=10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5097c5-e4b3-4500-8771-fd6d48183082",
   "metadata": {},
   "source": [
    "# Calculate time series of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae3c25-e694-4fbc-8afd-3c0b374b34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_func_gauss = SSIM(size_average=False, use_gauss=True)\n",
    "ssim_func_unfrm = SSIM(size_average=False, use_gauss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372accc2-158a-44c3-a16b-71411c1893c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = np.arange(4, 14, 2)\n",
    "\n",
    "for is_half in [False]:\n",
    "    for seed in tqdm([221958, 771155, 832180, 465838, 359178]):\n",
    "        for obs_grid_interval in tqdm(intervals, total=len(intervals)):\n",
    "\n",
    "            config_name = f\"lt4og{obs_grid_interval:02}_on1e-01_ep1000_lr1e-04_scT_bT_muT_a02_b02_sd{seed:06}\"\n",
    "\n",
    "            csv_path = f\"{CSV_DATA_DIR}/enkf_srda_err_time_series_{config_name}_with_init_noise.csv\"\n",
    "            if is_half:\n",
    "                csv_path = f\"{CSV_DATA_DIR}/enkf_srda_err_time_series_{config_name}_with_init_noise_half_test_data.csv\"\n",
    "\n",
    "            if os.path.exists(csv_path):\n",
    "                logger.info(f\"CSV already exists. {config_name}\")\n",
    "                continue\n",
    "\n",
    "            (\n",
    "                all_sr_forecast,\n",
    "                all_lr_omega,\n",
    "                all_hr_omega,\n",
    "                _,\n",
    "            ) = read_all_tmp_files(config_name)\n",
    "\n",
    "            num_batch_indices = all_hr_omega.shape[0]\n",
    "            if is_half:\n",
    "                num_batch_indices = num_batch_indices // 2\n",
    "            logger.info(f\"num_batch_indices = {num_batch_indices}\")\n",
    "\n",
    "            num_time_indices = MAX_TIME_INDEX_FOR_INTEGRATION\n",
    "            logger.info(f\"num_time_indices = {num_time_indices}\")\n",
    "\n",
    "            enkf_dir = f\"{ENKF_ROOT_DIR}/{config_name.replace(f'_sd{seed:06}', '_sd832180')}_with_init_noise\"\n",
    "\n",
    "            all_enkf_mean = [\n",
    "                np.load(f\"{enkf_dir}/ens_all_lr_{i:04}_with_init_noise.npy\")\n",
    "                for i in range(num_batch_indices)\n",
    "            ]\n",
    "            all_enkf_mean = np.stack(all_enkf_mean, axis=0)  # stack along batch dim\n",
    "            all_enkf_mean = np.mean(all_enkf_mean, axis=1)  # mean over ensemble dim\n",
    "\n",
    "            ts = [LR_DT * LR_NT * i_cycle + T0 for i_cycle in range(num_time_indices)]\n",
    "\n",
    "            df_results = pd.DataFrame()\n",
    "            df_results[\"Time\"] = ts[:num_time_indices]\n",
    "\n",
    "            for kind in [\"HR\", \"LR\"]:\n",
    "                gt = all_hr_omega[:num_batch_indices, :num_time_indices]\n",
    "                lr = all_lr_omega[:num_batch_indices, :num_time_indices]\n",
    "                srda = all_sr_forecast[:num_batch_indices, :num_time_indices]\n",
    "                enkf = all_enkf_mean[:num_batch_indices, :num_time_indices]\n",
    "\n",
    "                if kind == \"HR\":\n",
    "                    lr = interpolate_time_series(\n",
    "                        torch.from_numpy(lr), HR_NX, HR_NY\n",
    "                    ).numpy()\n",
    "                    enkf = interpolate_time_series(\n",
    "                        torch.from_numpy(enkf), HR_NX, HR_NY\n",
    "                    ).numpy()\n",
    "                elif kind == \"LR\":\n",
    "                    gt = interpolate_time_series(\n",
    "                        torch.from_numpy(gt), LR_NX, LR_NY\n",
    "                    ).numpy()\n",
    "                    srda = interpolate_time_series(\n",
    "                        torch.from_numpy(srda), LR_NX, LR_NY\n",
    "                    ).numpy()\n",
    "                else:\n",
    "                    raise NotImplementedError()\n",
    "\n",
    "                for label, data in zip([\"LR\", \"SRDA\", \"EnKF\"], [lr, srda, enkf]):\n",
    "                    assert gt.shape == data.shape\n",
    "\n",
    "                    errs = np.mean(\n",
    "                        np.abs(gt - data), axis=(-2, -1)\n",
    "                    )  # mean over x and y\n",
    "                    nrms = np.mean(np.abs(gt), axis=(-2, -1))\n",
    "\n",
    "                    mae = np.mean(errs, axis=0)  # mean over batch\n",
    "                    maer = np.mean(errs / nrms, axis=0)\n",
    "\n",
    "                    # Only time dim remains.\n",
    "                    assert mae.shape == maer.shape == (num_time_indices,)\n",
    "\n",
    "                    df_results[f\"MAE_{kind}_{label}\"] = mae\n",
    "                    df_results[f\"MAER_{kind}_{label}\"] = maer\n",
    "\n",
    "                    for ssim_kind, ssim_func in zip(\n",
    "                        [\"Gauss\", \"Uniform\"], [ssim_func_gauss, ssim_func_unfrm]\n",
    "                    ):\n",
    "\n",
    "                        ssim = ssim_func(\n",
    "                            img1=torch.from_numpy(gt).to(DEVICE),\n",
    "                            img2=torch.from_numpy(data).to(DEVICE),\n",
    "                        )\n",
    "                        ssim = torch.mean(\n",
    "                            ssim, dim=(0, 2, 3)\n",
    "                        )  # mean over batch, x, and y\n",
    "                        ssim = ssim.detach().cpu()\n",
    "\n",
    "                        # Only time dim remains.\n",
    "                        assert ssim.shape == (num_time_indices,)\n",
    "\n",
    "                        df_results[f\"SSIM_{ssim_kind}_{kind}_{label}\"] = 1 - ssim\n",
    "\n",
    "            df_results.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0973ea1-968d-434e-aba1-966365287105",
   "metadata": {},
   "source": [
    "# Plot error time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1444b-bc94-4221-be0a-d889e9ddf6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for resolution in [\"HR\", \"LR\"]:\n",
    "    intervals = np.arange(4, 14, 2)\n",
    "    for obs_grid_interval in tqdm(intervals, total=len(intervals)):\n",
    "\n",
    "        dict_dfs = {}\n",
    "        for seed in [221958, 771155, 832180, 465838, 359178]:\n",
    "            config_name = f\"lt4og{obs_grid_interval:02}_on1e-01_ep1000_lr1e-04_scT_bT_muT_a02_b02_sd{seed:06}\"\n",
    "            csv_path = f\"{CSV_DATA_DIR}/enkf_srda_err_time_series_{config_name}_with_init_noise.csv\"\n",
    "            dict_dfs[seed] = pd.read_csv(csv_path)\n",
    "\n",
    "        grid_ratio = OBS_GRID_RATIO[obs_grid_interval] * 100\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, sharex=True, figsize=[16, 3])\n",
    "\n",
    "        for ax, ycol in zip(axes, [\"MAER\", \"SSIM_Gauss\", \"SSIM_Uniform\"]):\n",
    "            xs = None\n",
    "\n",
    "            for ls, label in zip([\"-.\", \"-\", \"--\"], [\"LR\", \"SRDA\", \"EnKF\"]):\n",
    "                all_ys = []\n",
    "                for df in dict_dfs.values():\n",
    "                    all_ys.append(df[f\"{ycol}_{resolution}_{label}\"].values)\n",
    "                    if xs is None:\n",
    "                        xs = df[\"Time\"].values\n",
    "                    else:\n",
    "                        np.testing.assert_array_equal(xs, df[\"Time\"].values)\n",
    "\n",
    "                all_ys = np.stack(all_ys)\n",
    "                assert all_ys.shape == (5, MAX_TIME_INDEX_FOR_INTEGRATION)\n",
    "                # axis = batch, time\n",
    "\n",
    "                ys = np.mean(all_ys, axis=0)\n",
    "                diffs = all_ys - ys\n",
    "                min_diffs = -np.min(diffs, axis=0)\n",
    "                max_diffs = np.max(diffs, axis=0)\n",
    "                errs = np.stack([min_diffs, max_diffs])\n",
    "                assert errs.shape == (2, MAX_TIME_INDEX_FOR_INTEGRATION)\n",
    "                assert np.nanmax(errs) >= 0\n",
    "\n",
    "                if label == \"SRDA\":\n",
    "                    ax.errorbar(xs, ys, yerr=errs, label=label, ls=ls, capsize=2)\n",
    "                    # ax.plot(xs, ys, label=label, ls=ls)\n",
    "                else:\n",
    "                    ax.plot(xs, ys, label=label, ls=ls)\n",
    "\n",
    "            ax.set_xlabel(\"Time\")\n",
    "            ax.set_ylabel(f\"{ycol} ({resolution})\")\n",
    "            ax.set_title(f\"Observation grid ratio: {grid_ratio:.2f} %\")\n",
    "            ax.legend()\n",
    "            ax.set_xticks(np.linspace(4, 24, 6))\n",
    "\n",
    "            if ycol == \"MAER\":\n",
    "                ax.set_ylim(0, 1)\n",
    "            else:\n",
    "                ax.set_ylim(0.0, 0.4)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # if obs_grid_interval == 8:\n",
    "        #     fig.savefig(f\"{FIG_DIR}/err_time_series_enkf_vs_srda_{resolution}.jpg\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5213f1-6b93-43f9-accf-86aac19adb8e",
   "metadata": {},
   "source": [
    "# Dependency on observation grid ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa5833c-c652-4249-b5a4-81ba4bf7895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for resolution in [\"HR\", \"LR\"]:\n",
    "    intervals = np.arange(4, 14, 2)\n",
    "    xs = []\n",
    "    ys = {\n",
    "        \"MAER\": {\"SRDA\": [], \"EnKF\": []},\n",
    "        \"SSIM_Gauss\": {\"SRDA\": [], \"EnKF\": []},\n",
    "    }\n",
    "    y_min_errs = {\n",
    "        \"MAER\": {\"SRDA\": [], \"EnKF\": []},\n",
    "        \"SSIM_Gauss\": {\"SRDA\": [], \"EnKF\": []},\n",
    "    }\n",
    "    y_max_errs = {\n",
    "        \"MAER\": {\"SRDA\": [], \"EnKF\": []},\n",
    "        \"SSIM_Gauss\": {\"SRDA\": [], \"EnKF\": []},\n",
    "    }\n",
    "\n",
    "    for obs_grid_interval in tqdm(intervals, total=len(intervals)):\n",
    "        grid_ratio = OBS_GRID_RATIO[obs_grid_interval] * 100\n",
    "        xs.append(grid_ratio)\n",
    "\n",
    "        dict_dfs = {}\n",
    "        for seed in [221958, 771155, 832180, 465838, 359178]:\n",
    "            config_name = f\"lt4og{obs_grid_interval:02}_on1e-01_ep1000_lr1e-04_scT_bT_muT_a02_b02_sd{seed:06}\"\n",
    "            csv_path = f\"{CSV_DATA_DIR}/enkf_srda_err_time_series_{config_name}_with_init_noise.csv\"\n",
    "            dict_dfs[seed] = pd.read_csv(csv_path)\n",
    "\n",
    "        for ycol in [\"MAER\", \"SSIM_Gauss\"]:\n",
    "            for label in [\"SRDA\", \"EnKF\"]:\n",
    "                _ys = []\n",
    "                for df in dict_dfs.values():\n",
    "                    _ys.append(df[f\"{ycol}_{resolution}_{label}\"].mean())\n",
    "                _ys = np.array(_ys)\n",
    "                assert _ys.shape == (5,)\n",
    "\n",
    "                y = np.mean(_ys)\n",
    "                ys[ycol][label].append(y)\n",
    "                y_min_errs[ycol][label].append(-np.min(_ys - y))\n",
    "                y_max_errs[ycol][label].append(np.max(_ys - y))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, sharex=True, figsize=[12, 4])\n",
    "\n",
    "    for ax, ycol in zip(axes, [\"MAER\", \"SSIM_Gauss\"]):\n",
    "        for label, _ys in ys[ycol].items():\n",
    "            if label == \"SRDA\":\n",
    "                errs = np.array([y_min_errs[ycol][label], y_max_errs[ycol][label]])\n",
    "                ax.errorbar(xs, _ys, yerr=errs, fmt=\"o-\", label=label, capsize=5)\n",
    "            else:\n",
    "                ax.plot(xs, _ys, \"o-\", label=label)\n",
    "\n",
    "        ax.set_xlabel(\"Observation point ratio [%]\")\n",
    "        ax.set_ylabel(f\"{ycol} ({resolution})\")\n",
    "        ax.legend()\n",
    "\n",
    "        if ycol == \"MAER\":\n",
    "            ax.set_ylim(0.08, 0.4)\n",
    "            ax.set_yticks(np.linspace(0.08, 0.4, 5))\n",
    "        else:\n",
    "            ax.set_ylim(0.00, 0.16)\n",
    "            ax.set_yticks(np.linspace(0.00, 0.16, 5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # fig.savefig(f\"{FIG_DIR}/obs_point_vs_error_for_enkf_srda_{resolution}.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12439a7-2c19-46ac-a0cb-a5fce068527f",
   "metadata": {},
   "source": [
    "# Calculate time series of errors for all simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1706dca-dd45-4552-905d-aeffba13838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_func_gauss = SSIM(size_average=False, use_gauss=True)\n",
    "ssim_func_unfrm = SSIM(size_average=False, use_gauss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e10c6-4147-4749-8f97-dd5c2155460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = np.arange(4, 14, 2)\n",
    "\n",
    "for is_half in [False]:\n",
    "    for seed in tqdm([221958, 771155, 832180, 465838, 359178]):\n",
    "        for obs_grid_interval in tqdm(intervals, total=len(intervals)):\n",
    "\n",
    "            config_name = f\"lt4og{obs_grid_interval:02}_on1e-01_ep1000_lr1e-04_scT_bT_muT_a02_b02_sd{seed:06}\"\n",
    "\n",
    "            csv_path = f\"{CSV_DATA_DIR}/enkf_srda_err_time_series_{config_name}_with_init_noise_all_simulations.csv\"\n",
    "            if is_half:\n",
    "                csv_path = f\"{CSV_DATA_DIR}/enkf_srda_err_time_series_{config_name}_with_init_noise_half_test_data_all_simulations.csv\"\n",
    "\n",
    "            if os.path.exists(csv_path):\n",
    "                logger.info(f\"CSV already exists. {config_name}\")\n",
    "                continue\n",
    "\n",
    "            (\n",
    "                all_sr_forecast,\n",
    "                _,\n",
    "                all_hr_omega,\n",
    "                _,\n",
    "            ) = read_all_tmp_files(config_name)\n",
    "            del _\n",
    "            gc.collect()\n",
    "\n",
    "            num_batch_indices = all_hr_omega.shape[0]\n",
    "            if is_half:\n",
    "                num_batch_indices = num_batch_indices // 2\n",
    "\n",
    "            num_time_indices = MAX_TIME_INDEX_FOR_INTEGRATION\n",
    "\n",
    "            enkf_dir = f\"{ENKF_ROOT_DIR}/{config_name.replace(f'_sd{seed:06}', '_sd832180')}_with_init_noise\"\n",
    "\n",
    "            all_enkf_mean = [\n",
    "                np.load(f\"{enkf_dir}/ens_all_lr_{i:04}_with_init_noise.npy\")\n",
    "                for i in range(num_batch_indices)\n",
    "            ]\n",
    "            all_enkf_mean = np.stack(all_enkf_mean, axis=0)  # stack along batch dim\n",
    "            all_enkf_mean = np.mean(all_enkf_mean, axis=1)  # mean over ensemble dim\n",
    "            gc.collect()\n",
    "\n",
    "            ts = [LR_DT * LR_NT * i_cycle + T0 for i_cycle in range(num_time_indices)]\n",
    "            logger.info(\"All data have been read.\")\n",
    "\n",
    "            df_all_results = []\n",
    "            df_times = pd.DataFrame()\n",
    "            df_times[\"time\"] = ts[:num_time_indices]\n",
    "            df_all_results.append(df_times)\n",
    "\n",
    "            for kind in [\"HR\", \"LR\"]:\n",
    "                gt = all_hr_omega[:num_batch_indices, :num_time_indices]\n",
    "                srda = all_sr_forecast[:num_batch_indices, :num_time_indices]\n",
    "                enkf = all_enkf_mean[:num_batch_indices, :num_time_indices]\n",
    "\n",
    "                if kind == \"HR\":\n",
    "                    enkf = interpolate_time_series(\n",
    "                        torch.from_numpy(enkf), HR_NX, HR_NY\n",
    "                    ).numpy()\n",
    "                elif kind == \"LR\":\n",
    "                    gt = interpolate_time_series(\n",
    "                        torch.from_numpy(gt), LR_NX, LR_NY\n",
    "                    ).numpy()\n",
    "                    srda = interpolate_time_series(\n",
    "                        torch.from_numpy(srda), LR_NX, LR_NY\n",
    "                    ).numpy()\n",
    "                else:\n",
    "                    raise NotImplementedError()\n",
    "\n",
    "                for label, data in zip([\"SRDA\", \"EnKF\"], [srda, enkf]):\n",
    "                    logger.info(f\"{kind}:{label} is being evaluated\")\n",
    "                    assert gt.shape == data.shape\n",
    "\n",
    "                    mae = np.mean(np.abs(gt - data), axis=(-2, -1))  # mean over x and y\n",
    "                    nrms = np.mean(np.abs(gt), axis=(-2, -1))\n",
    "                    maer = mae / nrms\n",
    "\n",
    "                    # batch and time dims remain.\n",
    "                    assert (\n",
    "                        mae.shape == maer.shape == (num_batch_indices, num_time_indices)\n",
    "                    )\n",
    "\n",
    "                    cols = [\n",
    "                        f\"MAE_{kind}_{label}_{i:03}\" for i in range(num_batch_indices)\n",
    "                    ]\n",
    "                    df_all_results.append(\n",
    "                        pd.DataFrame(data=mae.transpose(), columns=cols)\n",
    "                    )\n",
    "\n",
    "                    cols = [\n",
    "                        f\"MAER_{kind}_{label}_{i:03}\" for i in range(num_batch_indices)\n",
    "                    ]\n",
    "                    df_all_results.append(\n",
    "                        pd.DataFrame(data=maer.transpose(), columns=cols)\n",
    "                    )\n",
    "\n",
    "                    for ssim_kind, ssim_func in zip(\n",
    "                        [\"Gauss\", \"Uniform\"], [ssim_func_gauss, ssim_func_unfrm]\n",
    "                    ):\n",
    "                        logger.info(f\"SSIM: {ssim_kind}\")\n",
    "                        ssim = ssim_func(\n",
    "                            img1=torch.from_numpy(gt).to(DEVICE),\n",
    "                            img2=torch.from_numpy(data).to(DEVICE),\n",
    "                        )\n",
    "                        ssim = torch.mean(ssim, dim=(2, 3))  # mean over x, and y\n",
    "                        ssim = ssim.detach().cpu().numpy()\n",
    "\n",
    "                        # Only time dim remains.\n",
    "                        assert ssim.shape == (num_batch_indices, num_time_indices)\n",
    "\n",
    "                        cols = [\n",
    "                            f\"SSIM_{ssim_kind}_{kind}_{label}_{i:03}\"\n",
    "                            for i in range(num_batch_indices)\n",
    "                        ]\n",
    "                        df_all_results.append(\n",
    "                            pd.DataFrame(data=ssim.transpose(), columns=cols)\n",
    "                        )\n",
    "\n",
    "            df_all_results = pd.concat(df_all_results, axis=1)\n",
    "            df_all_results.to_csv(csv_path, index=False)\n",
    "            logger.info(\"Finished\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ecf8b1-9bb7-42b0-b826-c8fc056f246f",
   "metadata": {},
   "source": [
    "# Plot error time series for all simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24679bd0-1464-4f72-8cd8-e3aecd6c2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = \"HR\"\n",
    "max_simulations = 250\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "intervals = np.arange(4, 14, 2)\n",
    "\n",
    "for seed in tqdm([221958, 771155, 832180, 465838, 359178]):\n",
    "    for obs_grid_interval in tqdm(intervals, total=len(intervals)):\n",
    "\n",
    "        config_name = f\"lt4og{obs_grid_interval:02}_on1e-01_ep1000_lr1e-04_scT_bT_muT_a02_b02_sd{seed:06}\"\n",
    "        csv_path = f\"{CSV_DATA_DIR}/enkf_srda_err_time_series_{config_name}_with_init_noise_all_simulations.csv\"\n",
    "        df_all_results = pd.read_csv(csv_path)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, sharex=True, figsize=[16, 4])\n",
    "\n",
    "        for ax, ycol in zip(axes, [\"MAER\", \"SSIM_Gauss\"]):\n",
    "            all_diffs = []\n",
    "            for i in range(max_simulations):\n",
    "                srda = df_all_results[f\"{ycol}_{resolution}_SRDA_{i:03}\"].values\n",
    "                enkf = df_all_results[f\"{ycol}_{resolution}_EnKF_{i:03}\"].values\n",
    "                all_diffs.append(srda - enkf)\n",
    "            all_diffs = np.stack(all_diffs, axis=0)\n",
    "\n",
    "            xs = df_all_results[\"time\"].values\n",
    "            ys = np.median(all_diffs, axis=0)\n",
    "            ys_low = np.quantile(all_diffs, 0.1, axis=0)\n",
    "            ys_high = np.quantile(all_diffs, 0.9, axis=0)\n",
    "\n",
    "            ax.plot(xs, ys_high, \"-\", label=\"90%tile\")\n",
    "            ax.plot(xs, ys, \"-\", label=\"50%tile\")\n",
    "            ax.plot(xs, ys_low, \"-\", label=\"10%tile\")\n",
    "\n",
    "            ax.axhline(0, ls=\"--\", color=\"k\")\n",
    "            ax.set_xlabel(\"Time\")\n",
    "            ax.set_ylabel(f\"Diff. {ycol}\")\n",
    "            ax.set_title(f\"Difference of {ycol}, SRDA minus EnKF\")\n",
    "            ax.legend()\n",
    "\n",
    "        r = OBS_GRID_RATIO[obs_grid_interval] * 100\n",
    "        plt.suptitle(f\"Seed = {seed}, Obs Point Ratio = {r:.2f} %\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c211b-a51b-4c2a-afee-46aa9eb391a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
