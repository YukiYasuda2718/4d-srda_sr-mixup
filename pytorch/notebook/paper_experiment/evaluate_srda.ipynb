{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41016fb-f196-4327-938c-d16ca860dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109dfe1-4752-4aba-9927-412cc9bac8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import DEBUG, INFO, WARNING, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not any([\"StreamHandler\" in str(handler) for handler in logger.handlers]):\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff3d0c-158a-4e55-8ad1-dcb95dc880f3",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a862ea7-9414-4e0d-b678-c5792d0e96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from cfd_model.initialization.periodic_channel_jet_initializer import calc_jet_forcing\n",
    "from cfd_model.interpolator.torch_interpolator import (\n",
    "    interpolate,\n",
    "    interpolate_time_series,\n",
    ")\n",
    "from IPython.display import display\n",
    "from src.sr_da_helper import (\n",
    "    get_observation_with_noise,\n",
    "    get_testdataset,\n",
    "    initialize_models,\n",
    "    make_invprocessed_sr,\n",
    "    make_models,\n",
    "    make_preprocessed_lr,\n",
    "    make_preprocessed_obs,\n",
    "    read_all_hr_omegas_with_combining,\n",
    ")\n",
    "from src.utils import set_seeds\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c0e21-af29-45ea-ae12-386de09d38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic\n",
    "set_seeds(42, use_deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9a573-5ea5-4e0e-b026-61f522908f60",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1324e8-fd38-4c97-8dfe-58b5351f7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = str((pathlib.Path(os.environ[\"PYTHONPATH\"]) / \"..\").resolve())\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08f7a7-cb6c-46c6-9e5a-d8c3997ddded",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DATA_DIR = \"/workspace/all_data/notebook/paper_experiment_01/data\"\n",
    "if not os.path.exists(TMP_DATA_DIR):\n",
    "    TMP_DATA_DIR = \"./data\"\n",
    "os.makedirs(TMP_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70fe06-9eb2-4a2c-aa38-6c7c437d4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DATA_DIR = \"./csv\"\n",
    "os.makedirs(CSV_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9dae1-f4e3-481f-a258-063f999e0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_DIR = \"./fig\"\n",
    "os.makedirs(FIG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c7881-319a-42a1-ba72-a6201c207ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = f\"{ROOT_DIR}/pytorch/config/paper_experiment_01\"\n",
    "CONFIG_PATHS = sorted(glob.glob(f\"{CONFIG_DIR}/*.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6578f8d-1400-4116-8a8b-34dfd811e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFD_DIR_NAME = \"jet02\"\n",
    "\n",
    "ASSIMILATION_PERIOD = 4\n",
    "START_TIME_INDEX = 16\n",
    "\n",
    "LR_NX = 32\n",
    "LR_NY = 17\n",
    "LR_DT = 5e-4\n",
    "LR_NT = 500\n",
    "\n",
    "HR_NX = 128\n",
    "HR_NY = 65\n",
    "\n",
    "Y0_MEAN = np.pi / 2.0\n",
    "SIGMA_MEAN = 0.4\n",
    "TAU0_MEAN = 0.3\n",
    "\n",
    "BETA = 0.1\n",
    "COEFF_LINEAR_DRAG = 1e-2\n",
    "ORDER_DIFFUSION = 2\n",
    "HR_COEFF_DIFFUSION = 1e-5\n",
    "LR_COEFF_DIFFUSION = 5e-5\n",
    "\n",
    "DT = LR_DT * LR_NT\n",
    "T0 = START_TIME_INDEX * LR_DT * LR_NT\n",
    "\n",
    "N_ENS_PER_CHUNK = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137352bf-399a-4a3b-9bdb-c37602bfe229",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    logger.info(\"GPU is used.\")\n",
    "else:\n",
    "    logger.error(\"No GPU. CPU is used.\")\n",
    "    raise Exception(\"No GPU. CPU is used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f6435-4779-4916-b622-59f1923abdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_CFD_CONFIG = {\n",
    "    \"nx\": LR_NX,\n",
    "    \"ny\": LR_NY,\n",
    "    \"coeff_linear_drag\": COEFF_LINEAR_DRAG,\n",
    "    \"coeff_diffusion\": LR_COEFF_DIFFUSION,\n",
    "    \"order_diffusion\": ORDER_DIFFUSION,\n",
    "    \"beta\": BETA,\n",
    "    \"device\": DEVICE,\n",
    "}\n",
    "\n",
    "INDEX_CONFIG = {\n",
    "    \"assimilation_period\": ASSIMILATION_PERIOD,\n",
    "    \"n_ens\": N_ENS_PER_CHUNK,\n",
    "    \"lr_nx\": LR_NX,\n",
    "    \"lr_ny\": LR_NY,\n",
    "    \"hr_nx\": HR_NX,\n",
    "    \"hr_ny\": HR_NY,\n",
    "    \"device\": DEVICE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b46390-586b-47bd-bf06-ac6a29862479",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = OrderedDict()\n",
    "\n",
    "for config_path in CONFIG_PATHS:\n",
    "    with open(config_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    config_name = os.path.basename(config_path).split(\".\")[0]\n",
    "    assert config_name not in CONFIGS\n",
    "\n",
    "    experiment_name = config_path.split(\"/\")[-2]\n",
    "    _dir = (\n",
    "        f\"/workspace/all_data/data/pytorch/DL_results/{experiment_name}/{config_name}\"\n",
    "    )\n",
    "    if not os.path.exists(_dir):\n",
    "        _dir = f\"{ROOT_DIR}/data/pytorch/DL_results/{experiment_name}/{config_name}\"\n",
    "\n",
    "    CONFIGS[config_name] = {\n",
    "        \"config\": config,\n",
    "        \"model_name\": config[\"model\"][\"model_name\"],\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"weight_path\": f\"{_dir}/weights.pth\",\n",
    "        \"learning_history_path\": f\"{_dir}/learning_history.csv\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af552217-c54d-43b1-924d-f8eeca749efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_GRID_RATIO = {\n",
    "    0: 0.0,\n",
    "    4: 0.06250000093132257,\n",
    "    5: 0.03999999910593033,\n",
    "    6: 0.027777777363856632,\n",
    "    7: 0.02040816326530612,\n",
    "    8: 0.015625000116415322,\n",
    "    9: 0.012345679127323775,\n",
    "    10: 0.010000000149011612,\n",
    "    11: 0.008264463206306716,\n",
    "    12: 0.006944444625534945,\n",
    "    13: 0.005917159876284691,\n",
    "    14: 0.005102040977882487,\n",
    "    15: 0.004444444572759999,\n",
    "    16: 0.003906250014551915,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6431ca-0f83-4079-9f33-381617617153",
   "metadata": {},
   "source": [
    "# Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b87a9-44b8-4ffa-a7f7-497390bcc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    dict_data: dict,\n",
    "    t: float,\n",
    "    obs: np.ndarray,\n",
    "    figsize: list = [20, 2],\n",
    "    write_out: bool = False,\n",
    "    ttl_header: str = \"\",\n",
    "    fig_file_name: str = \"\",\n",
    "    use_hr_space: bool = True,\n",
    "    vmin_omega: float = -9,\n",
    "    vmax_omega: float = 9,\n",
    "):\n",
    "\n",
    "    xs = np.linspace(0, 2 * np.pi, num=HR_NX, endpoint=False)\n",
    "    ys = np.linspace(0, np.pi, num=HR_NY, endpoint=True)\n",
    "    hr_x, hr_y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "    xs = np.linspace(0, 2 * np.pi, num=LR_NX, endpoint=False)\n",
    "    ys = np.linspace(0, np.pi, num=LR_NY, endpoint=True)\n",
    "    lr_x, lr_y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    fig, axes = plt.subplots(\n",
    "        1, len(dict_data), figsize=figsize, sharex=True, sharey=False\n",
    "    )\n",
    "\n",
    "    gt = None\n",
    "    for ax, (label, data) in zip(axes, dict_data.items()):\n",
    "        if label == \"LR\":\n",
    "            if use_hr_space:\n",
    "                data = interpolate(\n",
    "                    torch.from_numpy(data[None, :]), nx=HR_NX, ny=HR_NY, mode=\"nearest\"\n",
    "                ).numpy()\n",
    "        else:\n",
    "            if not use_hr_space:\n",
    "                data = interpolate(\n",
    "                    torch.from_numpy(data[None, :]), nx=LR_NX, ny=LR_NY\n",
    "                ).numpy()\n",
    "\n",
    "        if use_hr_space:\n",
    "            x, y = hr_x, hr_y\n",
    "        else:\n",
    "            x, y = lr_x, lr_y\n",
    "\n",
    "        d = np.squeeze(data)\n",
    "        if label == \"HR\":\n",
    "            gt = d\n",
    "            ttl = \"HR Ground Truth\"\n",
    "        else:\n",
    "            mae = np.mean(np.abs(gt - d))\n",
    "            ttl = label\n",
    "            ttl = f\"{label}\\nMAE={mae:.2f}\"\n",
    "\n",
    "        if use_hr_space:\n",
    "            assert d.shape == (HR_NX, HR_NY)\n",
    "        else:\n",
    "            assert d.shape == (LR_NX, LR_NY)\n",
    "\n",
    "        cnts = ax.pcolormesh(\n",
    "            x, y, d, cmap=\"twilight_shifted\", vmin=vmin_omega, vmax=vmax_omega\n",
    "        )\n",
    "        ax.set_title(ttl)\n",
    "\n",
    "        fig.colorbar(\n",
    "            cnts,\n",
    "            ax=ax,\n",
    "            ticks=[vmin_omega, vmin_omega / 2, 0, vmax_omega / 2, vmax_omega],\n",
    "            extend=\"both\",\n",
    "        )\n",
    "\n",
    "        ax.set_xlim([0, 2 * np.pi])\n",
    "        ax.set_ylim([0, np.pi])\n",
    "\n",
    "        if label == \"HR\" and use_hr_space:\n",
    "            obs = np.squeeze(obs).flatten()\n",
    "            obs_x = x.flatten()[~np.isnan(obs)]\n",
    "            obs_y = y.flatten()[~np.isnan(obs)]\n",
    "            ax.scatter(obs_x, obs_y, marker=\".\", s=1, c=\"k\")\n",
    "\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "    plt.suptitle(f\"{ttl_header}Time = {t}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if write_out:\n",
    "        fig.savefig(f\"{FIG_DIR}/{fig_file_name}.jpg\", dpi=300)\n",
    "        fig.savefig(f\"{FIG_DIR}/{fig_file_name}.eps\", dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_all_tmp_file_paths(config_name):\n",
    "    sr_analysis_file_path = f\"{TMP_DATA_DIR}/sr_analysis_{config_name}.npy\"\n",
    "    lr_omega_file_path = f\"{TMP_DATA_DIR}/lr_omega_{config_name}.npy\"\n",
    "    hr_omega_file_path = f\"{TMP_DATA_DIR}/hr_omega_{config_name}.npy\"\n",
    "    hr_obsrv_file_path = f\"{TMP_DATA_DIR}/hr_obsrv_{config_name}.npy\"\n",
    "\n",
    "    return (\n",
    "        sr_analysis_file_path,\n",
    "        lr_omega_file_path,\n",
    "        hr_omega_file_path,\n",
    "        hr_obsrv_file_path,\n",
    "    )\n",
    "\n",
    "\n",
    "def read_all_tmp_files(config_name):\n",
    "    (\n",
    "        sr_analysis_file_path,\n",
    "        lr_omega_file_path,\n",
    "        hr_omega_file_path,\n",
    "        hr_obsrv_file_path,\n",
    "    ) = get_all_tmp_file_paths(config_name)\n",
    "\n",
    "    return (\n",
    "        np.load(sr_analysis_file_path),\n",
    "        np.load(lr_omega_file_path),\n",
    "        np.load(hr_omega_file_path),\n",
    "        np.load(hr_obsrv_file_path),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70f68f-7fb3-446a-83a1-10518f1ea1db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bed46f-4a37-465a-b573-236c37539d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name, config_info in CONFIGS.items():\n",
    "    try:\n",
    "        df = pd.read_csv(config_info[\"learning_history_path\"])\n",
    "        assert len(df) == config_info[\"config\"][\"train\"][\"num_epochs\"]\n",
    "\n",
    "        continue\n",
    "        if config[\"train\"][\"seed\"] != 221958:\n",
    "            continue\n",
    "\n",
    "        plt.rcParams[\"font.size\"] = 15\n",
    "        fig = plt.figure(figsize=[7, 5])\n",
    "        ax = plt.subplot(111)\n",
    "\n",
    "        df.plot(\n",
    "            ax=ax,\n",
    "            xlabel=\"Epochs\",\n",
    "            ylabel=config_info[\"config\"][\"train\"][\"loss\"][\"name\"],\n",
    "        )\n",
    "        ax.set_title(config_name)\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "        # fig.savefig(f\"{FIG_DIR}/{config_name}_learning_curve.jpg\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(config_name)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28900295-e1d2-4d11-a69d-6fd076add4c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Perform SR-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a489e-ffcd-4bb7-9999-d1c99966ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name in tqdm(CONFIGS.keys(), total=len(CONFIGS)):\n",
    "    set_seeds(42, use_deterministic=True)\n",
    "\n",
    "    (\n",
    "        sr_analysis_file_path,\n",
    "        lr_omega_file_path,\n",
    "        hr_omega_file_path,\n",
    "        hr_obsrv_file_path,\n",
    "    ) = get_all_tmp_file_paths(config_name)\n",
    "\n",
    "    if (\n",
    "        os.path.exists(sr_analysis_file_path)\n",
    "        and os.path.exists(lr_omega_file_path)\n",
    "        and os.path.exists(hr_omega_file_path)\n",
    "        and os.path.exists(hr_obsrv_file_path)\n",
    "    ):\n",
    "        logger.info(f\"Results already exist. So skip {config_name}\")\n",
    "        continue\n",
    "\n",
    "    config_info = CONFIGS[config_name]\n",
    "    weight_path = config_info[\"weight_path\"]\n",
    "\n",
    "    if not os.path.exists(weight_path):\n",
    "        logger.info(f\"No weight file for {config_name}\")\n",
    "        continue\n",
    "    logger.info(f\"{config_name} is being evaluated\")\n",
    "\n",
    "    config = config_info[\"config\"]\n",
    "\n",
    "    test_dataset = get_testdataset(ROOT_DIR, config)\n",
    "    assert test_dataset.obs_time_interval == ASSIMILATION_PERIOD\n",
    "\n",
    "    all_hr_omegas = read_all_hr_omegas_with_combining(test_dataset.hr_file_paths)\n",
    "    assert all_hr_omegas.shape[1:] == (81, HR_NX, HR_NY)\n",
    "    assert all_hr_omegas.shape[0] % N_ENS_PER_CHUNK == 0\n",
    "\n",
    "    _, lr_forcing = calc_jet_forcing(\n",
    "        nx=LR_NX,\n",
    "        ny=LR_NY,\n",
    "        ne=1,\n",
    "        y0=Y0_MEAN,\n",
    "        sigma=SIGMA_MEAN,\n",
    "        tau0=TAU0_MEAN,\n",
    "    )\n",
    "\n",
    "    all_hr_obsrv, all_sr_analysis, all_lr_omega = [], [], []\n",
    "\n",
    "    for hr_omegas in tqdm(\n",
    "        torch.split(all_hr_omegas, N_ENS_PER_CHUNK),\n",
    "        total=(all_hr_omegas.shape[0] // N_ENS_PER_CHUNK),\n",
    "    ):\n",
    "        sr_model, lr_model, srda_model = make_models(config, weight_path, LR_CFD_CONFIG)\n",
    "\n",
    "        initialize_models(\n",
    "            t0=T0,\n",
    "            hr_omega0=hr_omegas[:, 0],  # first time index\n",
    "            lr_forcing=lr_forcing,\n",
    "            lr_model=lr_model,\n",
    "            srda_model=srda_model,\n",
    "            **INDEX_CONFIG,\n",
    "        )\n",
    "\n",
    "        hr_obsrv = get_observation_with_noise(hr_omegas, test_dataset, **INDEX_CONFIG)\n",
    "        assert hr_obsrv.shape == hr_omegas.shape\n",
    "\n",
    "        ts, hr_obs, lr_omega, lr_forecast, sr_analysis = [], [], [], [], []\n",
    "        last_omega0 = None\n",
    "        max_time_index = hr_omegas.shape[1]\n",
    "\n",
    "        for i_cycle in tqdm(range(max_time_index)):\n",
    "            logger.debug(f\"Start: i_cycle = {i_cycle}, t = {lr_model.t:.2f}\")\n",
    "\n",
    "            ts.append(lr_model.t)\n",
    "            lr_omega.append(lr_model.omega.cpu().clone())\n",
    "            lr_forecast.append(srda_model.omega.cpu().clone())\n",
    "\n",
    "            if config[\"data\"][\"use_observation\"] and i_cycle % ASSIMILATION_PERIOD == 0:\n",
    "                hr_obs.append(hr_obsrv[:, i_cycle])\n",
    "            else:\n",
    "                hr_obs.append(torch.full_like(hr_obsrv[:, i_cycle], torch.nan))\n",
    "\n",
    "            if i_cycle > 0 and i_cycle % ASSIMILATION_PERIOD == 0:\n",
    "                x = make_preprocessed_lr(\n",
    "                    lr_forecast,\n",
    "                    last_omega0,\n",
    "                    test_dataset,\n",
    "                    **INDEX_CONFIG,\n",
    "                )\n",
    "                o = make_preprocessed_obs(\n",
    "                    hr_obs,\n",
    "                    test_dataset,\n",
    "                    **INDEX_CONFIG,\n",
    "                )\n",
    "\n",
    "                if not config[\"data\"].get(\"use_lr_forecast\", True):\n",
    "                    x = torch.full_like(x, test_dataset.missing_value)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    sr = sr_model(x, o).detach().cpu().clone()\n",
    "                sr = make_invprocessed_sr(\n",
    "                    sr,\n",
    "                    test_dataset,\n",
    "                    **INDEX_CONFIG,\n",
    "                )\n",
    "\n",
    "                last_omega0 = interpolate(sr[-1, :], nx=LR_NX, ny=LR_NY, mode=\"bicubic\")\n",
    "                srda_model.initialize(t0=srda_model.t, omega0=last_omega0)\n",
    "\n",
    "                i_start = 0 if len(sr_analysis) == 0 else 1\n",
    "                for it in range(i_start, sr.shape[0]):\n",
    "                    sr_analysis.append(sr[it])\n",
    "\n",
    "                logger.debug(f\"Assimilation at i = {i_cycle}\")\n",
    "\n",
    "            lr_model.time_integrate(dt=LR_DT, nt=LR_NT, hide_progress_bar=True)\n",
    "            lr_model.calc_grid_data()\n",
    "\n",
    "            srda_model.time_integrate(dt=LR_DT, nt=LR_NT, hide_progress_bar=True)\n",
    "            srda_model.calc_grid_data()\n",
    "\n",
    "        # Stack along time dim\n",
    "        all_hr_obsrv.append(torch.stack(hr_obs, dim=1))\n",
    "        all_lr_omega.append(torch.stack(lr_omega, dim=1))\n",
    "        all_sr_analysis.append(torch.stack(sr_analysis, dim=1))\n",
    "\n",
    "        del sr_model, lr_model, srda_model\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = gc.collect()\n",
    "\n",
    "    # Stack along ensemble (batch) dim\n",
    "    all_hr_obsrv = torch.cat(all_hr_obsrv, dim=0).to(torch.float32).numpy()\n",
    "    all_lr_omega = torch.cat(all_lr_omega, dim=0).to(torch.float32).numpy()\n",
    "    all_sr_analysis = torch.cat(all_sr_analysis, dim=0).to(torch.float32).numpy()\n",
    "    all_hr_omegas = all_hr_omegas.to(torch.float32).numpy()\n",
    "\n",
    "    np.save(hr_obsrv_file_path, all_hr_obsrv)\n",
    "    np.save(lr_omega_file_path, all_lr_omega)\n",
    "    np.save(sr_analysis_file_path, all_sr_analysis)\n",
    "    np.save(hr_omega_file_path, all_hr_omegas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c438d6-828f-4b23-a7f2-d0da7ee9f690",
   "metadata": {},
   "source": [
    "# Anlyze errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c7ad1-264b-48ea-b987-48b3f97b6070",
   "metadata": {},
   "source": [
    "## Make csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac869ac4-bc99-42fb-9ec9-a39c69dc5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name in tqdm(CONFIGS.keys(), total=len(CONFIGS)):\n",
    "    try:\n",
    "        csv_file = f\"{CSV_DATA_DIR}/hr_err_time_series_{config_name}_with_mae_ratio.csv\"\n",
    "\n",
    "        if os.path.exists(csv_file):\n",
    "            continue\n",
    "\n",
    "        (\n",
    "            all_sr_analysis,\n",
    "            all_lr_omega,\n",
    "            all_hr_omega,\n",
    "            _,\n",
    "        ) = read_all_tmp_files(config_name)\n",
    "\n",
    "        max_time_index = all_hr_omega.shape[1]\n",
    "        ts = [LR_DT * LR_NT * i_cycle + T0 for i_cycle in range(max_time_index)]\n",
    "\n",
    "        _lr = interpolate_time_series(\n",
    "            torch.from_numpy(all_lr_omega), HR_NX, HR_NY\n",
    "        ).numpy()\n",
    "        assert _lr.shape == all_hr_omega.shape == (500, 81, HR_NX, HR_NY)\n",
    "\n",
    "        # mean over x and y dims\n",
    "        _lr_err1 = np.mean(np.abs(_lr - all_hr_omega), axis=(-2, -1))\n",
    "        _lr_err2 = np.mean(np.abs(all_hr_omega), axis=(-2, -1))\n",
    "        # mean over ensemble dim\n",
    "        lr = np.mean(_lr_err1, axis=(0,))\n",
    "        lr_ratio = np.mean(_lr_err1 / _lr_err2, axis=(0,))\n",
    "\n",
    "        assert all_sr_analysis.shape == all_hr_omega.shape == (500, 81, HR_NX, HR_NY)\n",
    "\n",
    "        _sr_err1 = np.mean(np.abs(all_sr_analysis - all_hr_omega), axis=(-2, -1))\n",
    "        _sr_err2 = np.mean(np.abs(all_hr_omega), axis=(-2, -1))\n",
    "        sr = np.mean(_sr_err1, axis=(0,))\n",
    "        sr_ratio = np.mean(_sr_err1 / _sr_err2, axis=(0,))\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"Time\"] = ts\n",
    "        df[\"ErrLR(bicubic)\"] = lr\n",
    "        df[\"ErrRatioLR(bicubic)\"] = lr_ratio\n",
    "        df[\"ErrSR\"] = sr\n",
    "        df[\"ErrRatioSR\"] = sr_ratio\n",
    "        df.to_csv(csv_file, index=False)\n",
    "    except Exception as e:\n",
    "        logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c708887-aa7b-4709-9992-b897f5ab9928",
   "metadata": {},
   "source": [
    "## Analyze csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454d812-c3c3-4183-a742-9e0fe9499836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(index=CONFIGS.keys())\n",
    "\n",
    "for config_name in tqdm(CONFIGS.keys(), total=len(CONFIGS)):\n",
    "    csv_file = f\"{CSV_DATA_DIR}/hr_err_time_series_{config_name}_with_mae_ratio.csv\"\n",
    "    if not os.path.exists(csv_file):\n",
    "        logger.error(f\"{csv_file} does not exist!\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    config = CONFIGS[config_name][\"config\"]\n",
    "\n",
    "    df_results.loc[config_name, \"AveErrSR\"] = df[\"ErrSR\"].mean()\n",
    "    df_results.loc[config_name, \"MaxErrSR\"] = df[\"ErrSR\"].max()\n",
    "    df_results.loc[config_name, \"MinErrSR\"] = df[\"ErrSR\"].min()\n",
    "    df_results.loc[config_name, \"StdErrSR\"] = df[\"ErrSR\"].std()\n",
    "    df_results.loc[config_name, \"Max-MinErrSR\"] = (\n",
    "        df_results.loc[config_name, \"MaxErrSR\"]\n",
    "        - df_results.loc[config_name, \"MinErrSR\"]\n",
    "    )\n",
    "\n",
    "    df_results.loc[config_name, \"UseObs\"] = config[\"data\"][\"use_observation\"]\n",
    "    df_results.loc[config_name, \"ObsGridInterval\"] = config[\"data\"][\"obs_grid_interval\"]\n",
    "    df_results.loc[config_name, \"ObsGridRatio\"] = (\n",
    "        OBS_GRID_RATIO[config[\"data\"][\"obs_grid_interval\"]] * 100\n",
    "    )\n",
    "    df_results.loc[config_name, \"ObsNoiseStd\"] = config[\"data\"][\"obs_noise_std\"]\n",
    "\n",
    "    df_results.loc[config_name, \"LrTimeInterval\"] = config[\"data\"][\"lr_time_interval\"]\n",
    "    df_results.loc[config_name, \"UseSkipConn\"] = config[\"model\"][\n",
    "        \"use_global_skip_connection\"\n",
    "    ]\n",
    "    df_results.loc[config_name, \"UseMixup\"] = config[\"data\"][\"use_mixup\"]\n",
    "    df_results.loc[config_name, \"alpha\"] = config[\"data\"][\"beta_dist_alpha\"]\n",
    "    df_results.loc[config_name, \"beta\"] = config[\"data\"][\"beta_dist_beta\"]\n",
    "    df_results.loc[config_name, \"UseLrForecast\"] = config[\"data\"].get(\n",
    "        \"use_lr_forecast\", True\n",
    "    )\n",
    "    df_results.loc[config_name, \"Seed\"] = config[\"train\"][\"seed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e1d76-c65d-4901-b05f-278a92984045",
   "metadata": {},
   "outputs": [],
   "source": [
    "for grid_ratio, grp in df_results.groupby(\"ObsGridRatio\"):\n",
    "    display(f\"Grid Ratio = {grid_ratio*100}\")\n",
    "    display(grp.sort_values(\"MaxErrSR\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450590b-8406-4253-a0ec-c007a7257128",
   "metadata": {},
   "source": [
    "# Make figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b187f65-0d10-456c-9ad4-c227aac0d2f7",
   "metadata": {},
   "source": [
    "## Obs grid ratio, groupby use mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58abe2b-a378-431f-8740-f9f4f674b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "ycol = \"AveErrSR\"\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "df = df_results.sort_values(\"ObsGridRatio\")\n",
    "df = df[(df[\"UseObs\"] == True) & (df[\"UseLrForecast\"] == True)]\n",
    "\n",
    "data = df[(df[\"UseMixup\"] == False)]\n",
    "\n",
    "data = data.groupby(\"ObsGridRatio\")[ycol].agg(func=[\"mean\", \"count\", \"min\", \"max\"])\n",
    "ys = data[\"mean\"]\n",
    "errs = np.array([ys - data[\"min\"], data[\"max\"] - ys])\n",
    "assert len(ys) == 5 and set(data[\"count\"]) == {5}\n",
    "\n",
    "ax.errorbar(data.index, ys, yerr=errs, fmt=\"o-\", label=\"No Mixup\", capsize=5)\n",
    "\n",
    "\n",
    "data = df[(df[\"UseMixup\"] == True) & (df[\"beta\"] == 2)]\n",
    "\n",
    "data = data.groupby(\"ObsGridRatio\")[ycol].agg(func=[\"mean\", \"count\", \"min\", \"max\"])\n",
    "ys = data[\"mean\"]\n",
    "errs = np.array([ys - data[\"min\"], data[\"max\"] - ys])\n",
    "assert len(ys) == 5 and set(data[\"count\"]) == {5}\n",
    "\n",
    "ax.errorbar(data.index, ys, yerr=errs, fmt=\"o-\", label=\"Use Mixup\", capsize=5)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"Ave MAE\")\n",
    "ax.set_xlabel(\"Observation point ratio [%]\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133c82a-ce18-4377-a7c3-6ff4ff46cf89",
   "metadata": {},
   "source": [
    "## Using only Observation or not (no LR or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89275d09-8415-4876-a687-df081b32f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol = \"AveErrSR\"\n",
    "\n",
    "for seed in [221958, 771155, 832180, 465838, 359178]:\n",
    "    xs, ys, ys_no_lr = [], [], []\n",
    "    for obs_grid_interval in range(4, 14, 2):\n",
    "        try:\n",
    "            config_name_using_lr = f\"lt4og{obs_grid_interval:02}_on1e-01_ep1000_lr1e-04_scT_muT_a02_b02_sd{seed:06}\"\n",
    "            err = df_results.loc[config_name_using_lr, ycol]\n",
    "\n",
    "            config_name_no_lr = config_name_using_lr.replace(\"_muT_\", \"_muF_\") + \"_noLR\"\n",
    "            err_no_lr = df_results.loc[config_name_no_lr, ycol]\n",
    "\n",
    "            xs.append(OBS_GRID_RATIO[obs_grid_interval])\n",
    "            ys.append(err)\n",
    "            ys_no_lr.append(err_no_lr)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    ax.plot(xs, ys, \"o-\", label=\"Using Obs and LR\")\n",
    "    ax.plot(xs, ys_no_lr, \"o-\", label=\"Using Obs but No LR\")\n",
    "\n",
    "    ax.set_ylabel(\"MAE (time ave.)\")\n",
    "    ax.set_xlabel(\"Observation grid ratio [%]\")\n",
    "    ax.set_title(f\"Seed = {seed}\")\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5069fa80-32ff-47f6-98da-1d5bbf33cc44",
   "metadata": {},
   "source": [
    "## Error time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1bd98-b5e5-4e34-a85f-86eab2bed86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_grid_interval = 12\n",
    "\n",
    "for seed in [221958, 771155, 832180, 465838, 359178]:\n",
    "    config_name_without_obs = (\n",
    "        f\"lt4og00_on1e-01_ep1000_lr1e-04_scT_muT_a02_b02_sd{seed:06}\"\n",
    "    )\n",
    "    config_name_using_obs = config_name_without_obs.replace(\n",
    "        \"og00\", f\"og{obs_grid_interval:02}\"\n",
    "    )\n",
    "    config_name_only_obs = config_name_using_obs.replace(\"muT\", \"muF\") + \"_noLR\"\n",
    "\n",
    "    df_without_obs = pd.read_csv(\n",
    "        f\"{CSV_DATA_DIR}/hr_err_time_series_{config_name_without_obs}_with_mae_ratio.csv\"\n",
    "    )\n",
    "    df_using_obs = pd.read_csv(\n",
    "        f\"{CSV_DATA_DIR}/hr_err_time_series_{config_name_using_obs}_with_mae_ratio.csv\"\n",
    "    )\n",
    "    df_only_obs = pd.read_csv(\n",
    "        f\"{CSV_DATA_DIR}/hr_err_time_series_{config_name_only_obs}_with_mae_ratio.csv\"\n",
    "    )\n",
    "\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "    fig = plt.figure(figsize=[8, 4])\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    ax.plot(df_using_obs[\"Time\"], df_using_obs[\"ErrSR\"], \"-\", label=\"SRDA\")\n",
    "    ax.plot(df_without_obs[\"Time\"], df_without_obs[\"ErrSR\"], \"--\", label=\"Only SR\")\n",
    "    ax.plot(df_only_obs[\"Time\"], df_only_obs[\"ErrSR\"], \"--\", label=\"Only Obs\")\n",
    "\n",
    "    ax.plot(\n",
    "        df_without_obs[\"Time\"],\n",
    "        df_without_obs[\"ErrLR(bicubic)\"],\n",
    "        \"-.\",\n",
    "        label=\"No SR or DA\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Observation point ratio = {OBS_GRID_RATIO[obs_grid_interval]*100:.2f} %\"\n",
    "    )\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"MAE\")\n",
    "    ax.set_title(f\"Seed = {seed}\")\n",
    "\n",
    "    lg = ax.legend(\n",
    "        bbox_to_anchor=(1.05, 1.0),\n",
    "        loc=\"upper left\",\n",
    "        ncol=1,\n",
    "        fontsize=16,\n",
    "        framealpha=1,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e080a44-21d4-46f1-ab69-995f127596aa",
   "metadata": {},
   "source": [
    "## Vorticity snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d132773-16cc-45a5-9a98-286e5c917c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_config_name = \"lt4og12_on1e-01_ep1000_lr1e-04_scT_muT_a02_b02_sd221958\"\n",
    "\n",
    "(\n",
    "    all_sr_analysis_with_noise,\n",
    "    all_lr_omega,\n",
    "    all_hr_omega,\n",
    "    all_hr_obsrv,\n",
    ") = read_all_tmp_files(target_config_name)\n",
    "\n",
    "target_config_name = \"lt4og12_on1e-01_ep1000_lr1e-04_scT_muF_a02_b02_sd221958\"\n",
    "\n",
    "all_sr_analysis_without_noise, _, _, _ = read_all_tmp_files(target_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb094cc-a716-4389-9f94-132930036a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_ensemble in [43, 46, 48, 70, 91, 107, 154, 156, 163, 185]:\n",
    "    for i_cycle in [40, 80]:\n",
    "\n",
    "        t = (i_cycle + START_TIME_INDEX) * DT\n",
    "\n",
    "        dict_data = {\n",
    "            \"HR\": all_hr_omega[i_ensemble, i_cycle],\n",
    "            \"LR\": all_lr_omega[i_ensemble, i_cycle],\n",
    "            \"SRDA(noise)\": all_sr_analysis_with_noise[i_ensemble, i_cycle],\n",
    "            \"SRDA(no noise)\": all_sr_analysis_without_noise[i_ensemble, i_cycle],\n",
    "        }\n",
    "\n",
    "        plot(\n",
    "            dict_data,\n",
    "            t,\n",
    "            obs=all_hr_obsrv[i_ensemble, i_cycle],\n",
    "            figsize=[12, 4.0],\n",
    "            ttl_header=f\"i_ens = {i_ensemble}, \",\n",
    "            fig_file_name=f\"snapshot_use_obs_{i_ensemble:03}_t_{int(t):03}\",\n",
    "            write_out=False,\n",
    "            use_hr_space=True,\n",
    "            vmin_omega=-10,\n",
    "            vmax_omega=10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263d84e-1137-41ca-8e7b-bf00be17f4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
