{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41016fb-f196-4327-938c-d16ca860dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109dfe1-4752-4aba-9927-412cc9bac8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import DEBUG, INFO, WARNING, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not any([\"StreamHandler\" in str(handler) for handler in logger.handlers]):\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff3d0c-158a-4e55-8ad1-dcb95dc880f3",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a862ea7-9414-4e0d-b678-c5792d0e96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from cfd_model.interpolator.torch_interpolator import (\n",
    "    interpolate,\n",
    "    interpolate_time_series,\n",
    ")\n",
    "from IPython.display import display\n",
    "from src.model_maker import make_model\n",
    "from src.sr_da_helper import get_testdataloader\n",
    "from src.utils import AverageMeter, set_seeds\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c0e21-af29-45ea-ae12-386de09d38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic\n",
    "set_seeds(42, use_deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9a573-5ea5-4e0e-b026-61f522908f60",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1324e8-fd38-4c97-8dfe-58b5351f7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = str((pathlib.Path(os.environ[\"PYTHONPATH\"]) / \"..\").resolve())\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08f7a7-cb6c-46c6-9e5a-d8c3997ddded",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DATA_DIR = \"/workspace/all_data/notebook/paper_experiment_01/data\"\n",
    "if not os.path.exists(TMP_DATA_DIR):\n",
    "    TMP_DATA_DIR = \"./data\"\n",
    "os.makedirs(TMP_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70fe06-9eb2-4a2c-aa38-6c7c437d4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DATA_DIR = \"./csv\"\n",
    "os.makedirs(CSV_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9dae1-f4e3-481f-a258-063f999e0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_DIR = \"./fig\"\n",
    "os.makedirs(FIG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c7881-319a-42a1-ba72-a6201c207ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = f\"{ROOT_DIR}/pytorch/config/paper_experiment_01\"\n",
    "CONFIG_PATHS = sorted(glob.glob(f\"{CONFIG_DIR}/*.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6578f8d-1400-4116-8a8b-34dfd811e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFD_DIR_NAME = \"jet12\"\n",
    "\n",
    "ASSIMILATION_PERIOD = 4\n",
    "START_TIME_INDEX = 16\n",
    "\n",
    "LR_NX = 32\n",
    "LR_NY = 17\n",
    "LR_DT = 5e-4\n",
    "LR_NT = 500\n",
    "\n",
    "HR_NX = 128\n",
    "HR_NY = 65\n",
    "\n",
    "Y0_MEAN = np.pi / 2.0\n",
    "SIGMA_MEAN = 0.4\n",
    "TAU0_MEAN = 0.3\n",
    "\n",
    "BETA = 0.1\n",
    "COEFF_LINEAR_DRAG = 1e-2\n",
    "ORDER_DIFFUSION = 2\n",
    "HR_COEFF_DIFFUSION = 1e-5\n",
    "LR_COEFF_DIFFUSION = 5e-5\n",
    "\n",
    "DT = LR_DT * LR_NT\n",
    "T0 = START_TIME_INDEX * LR_DT * LR_NT\n",
    "\n",
    "N_ENS_PER_CHUNK = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137352bf-399a-4a3b-9bdb-c37602bfe229",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    logger.info(\"GPU is used.\")\n",
    "else:\n",
    "    logger.error(\"No GPU. CPU is used.\")\n",
    "    raise Exception(\"No GPU. CPU is used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b46390-586b-47bd-bf06-ac6a29862479",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = OrderedDict()\n",
    "\n",
    "for config_path in CONFIG_PATHS:\n",
    "    with open(config_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    config_name = os.path.basename(config_path).split(\".\")[0]\n",
    "    assert config_name not in CONFIGS\n",
    "\n",
    "    experiment_name = config_path.split(\"/\")[-2]\n",
    "    _dir = (\n",
    "        f\"/workspace/all_data/data/pytorch/DL_results/{experiment_name}/{config_name}\"\n",
    "    )\n",
    "    if not os.path.exists(_dir):\n",
    "        _dir = f\"{ROOT_DIR}/data/pytorch/DL_results/{experiment_name}/{config_name}\"\n",
    "\n",
    "    CONFIGS[config_name] = {\n",
    "        \"config\": config,\n",
    "        \"model_name\": config[\"model\"][\"model_name\"],\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"weight_path\": f\"{_dir}/weights.pth\",\n",
    "        \"learning_history_path\": f\"{_dir}/learning_history.csv\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af552217-c54d-43b1-924d-f8eeca749efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_GRID_RATIO = {\n",
    "    0: 0.0,\n",
    "    4: 0.06250000093132257,\n",
    "    5: 0.03999999910593033,\n",
    "    6: 0.027777777363856632,\n",
    "    7: 0.02040816326530612,\n",
    "    8: 0.015625000116415322,\n",
    "    9: 0.012345679127323775,\n",
    "    10: 0.010000000149011612,\n",
    "    11: 0.008264463206306716,\n",
    "    12: 0.006944444625534945,\n",
    "    13: 0.005917159876284691,\n",
    "    14: 0.005102040977882487,\n",
    "    15: 0.004444444572759999,\n",
    "    16: 0.003906250014551915,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6431ca-0f83-4079-9f33-381617617153",
   "metadata": {},
   "source": [
    "# Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b87a9-44b8-4ffa-a7f7-497390bcc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    dict_data: dict,\n",
    "    t: float,\n",
    "    obs: np.ndarray,\n",
    "    figsize: list = [20, 2],\n",
    "    write_out: bool = False,\n",
    "    ttl_header: str = \"\",\n",
    "    fig_file_name: str = \"\",\n",
    "    use_hr_space: bool = True,\n",
    "    vmin_omega: float = -9,\n",
    "    vmax_omega: float = 9,\n",
    "):\n",
    "\n",
    "    xs = np.linspace(0, 2 * np.pi, num=HR_NX, endpoint=False)\n",
    "    ys = np.linspace(0, np.pi, num=HR_NY - 1, endpoint=False)\n",
    "    hr_x, hr_y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "    xs = np.linspace(0, 2 * np.pi, num=LR_NX, endpoint=False)\n",
    "    ys = np.linspace(0, np.pi, num=LR_NY - 1, endpoint=False)\n",
    "    lr_x, lr_y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    fig, axes = plt.subplots(\n",
    "        1, len(dict_data), figsize=figsize, sharex=True, sharey=False\n",
    "    )\n",
    "\n",
    "    gt = None\n",
    "    for ax, (label, data) in zip(axes, dict_data.items()):\n",
    "        if label == \"LR\":\n",
    "            if use_hr_space:\n",
    "                data = interpolate(\n",
    "                    torch.from_numpy(data[None, :]),\n",
    "                    nx=HR_NX,\n",
    "                    ny=HR_NY - 1,\n",
    "                    mode=\"nearest\",\n",
    "                ).numpy()\n",
    "        else:\n",
    "            if not use_hr_space:\n",
    "                data = interpolate(\n",
    "                    torch.from_numpy(data[None, :]), nx=LR_NX, ny=LR_NY - 1\n",
    "                ).numpy()\n",
    "\n",
    "        if use_hr_space:\n",
    "            x, y = hr_x, hr_y\n",
    "        else:\n",
    "            x, y = lr_x, lr_y\n",
    "\n",
    "        d = np.squeeze(data)\n",
    "        if label == \"HR\":\n",
    "            gt = d\n",
    "            ttl = \"HR Ground Truth\"\n",
    "        else:\n",
    "            mae = np.mean(np.abs(gt - d))\n",
    "            ttl = label\n",
    "            ttl = f\"{label}\\nMAE={mae:.2f}\"\n",
    "\n",
    "        if use_hr_space:\n",
    "            assert d.shape == (HR_NX, HR_NY - 1)\n",
    "        else:\n",
    "            assert d.shape == (LR_NX, LR_NY - 1)\n",
    "\n",
    "        cnts = ax.pcolormesh(\n",
    "            x, y, d, cmap=\"twilight_shifted\", vmin=vmin_omega, vmax=vmax_omega\n",
    "        )\n",
    "        ax.set_title(ttl)\n",
    "\n",
    "        fig.colorbar(\n",
    "            cnts,\n",
    "            ax=ax,\n",
    "            ticks=[vmin_omega, vmin_omega / 2, 0, vmax_omega / 2, vmax_omega],\n",
    "            extend=\"both\",\n",
    "        )\n",
    "\n",
    "        ax.set_xlim([0, 2 * np.pi])\n",
    "        ax.set_ylim([0, np.pi])\n",
    "\n",
    "        if label == \"HR\" and use_hr_space:\n",
    "            obs = np.squeeze(obs).flatten()\n",
    "            obs_x = x.flatten()[~np.isnan(obs)]\n",
    "            obs_y = y.flatten()[~np.isnan(obs)]\n",
    "            ax.scatter(obs_x, obs_y, marker=\".\", s=1, c=\"k\")\n",
    "\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "    plt.suptitle(f\"{ttl_header}Time = {t}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if write_out:\n",
    "        fig.savefig(f\"{FIG_DIR}/{fig_file_name}.jpg\", dpi=300)\n",
    "        fig.savefig(f\"{FIG_DIR}/{fig_file_name}.eps\", dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70f68f-7fb3-446a-83a1-10518f1ea1db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bed46f-4a37-465a-b573-236c37539d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name, config_info in CONFIGS.items():\n",
    "    try:\n",
    "        df = pd.read_csv(config_info[\"learning_history_path\"])\n",
    "        assert len(df) == config_info[\"config\"][\"train\"][\"num_epochs\"]\n",
    "\n",
    "        continue\n",
    "\n",
    "        plt.rcParams[\"font.size\"] = 15\n",
    "        fig = plt.figure(figsize=[7, 5])\n",
    "        ax = plt.subplot(111)\n",
    "\n",
    "        df.plot(\n",
    "            ax=ax,\n",
    "            xlabel=\"Epochs\",\n",
    "            ylabel=config_info[\"config\"][\"train\"][\"loss\"][\"name\"],\n",
    "        )\n",
    "        ax.set_title(config_name)\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "        # fig.savefig(f\"{FIG_DIR}/{config_name}_learning_curve.jpg\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(config_name)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28900295-e1d2-4d11-a69d-6fd076add4c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916de920-3b05-470e-b685-9c21f4acf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_result = f\"{CSV_DATA_DIR}/mae_scores_using_testdataset.csv\"\n",
    "\n",
    "if os.path.exists(csv_result):\n",
    "    df_results = pd.read_csv(csv_result).set_index(\"Unnamed: 0\")\n",
    "    print(\"DF is read from csv.\")\n",
    "else:\n",
    "    df_results = pd.DataFrame()\n",
    "    print(\"DF is created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ec82a-6cdf-4931-b74f-4fc0c680539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_loops = 100\n",
    "\n",
    "for config_name in tqdm(CONFIGS.keys(), total=len(CONFIGS)):\n",
    "    if config_name in df_results.index:\n",
    "        logger.info(f\"Result of {config_name} already exists. So skip it.\")\n",
    "        continue\n",
    "\n",
    "    set_seeds(42, use_deterministic=True)\n",
    "\n",
    "    config_info = CONFIGS[config_name]\n",
    "    config = config_info[\"config\"]\n",
    "    weight_path = config_info[\"weight_path\"]\n",
    "\n",
    "    if not os.path.exists(weight_path):\n",
    "        print(f\"Weight of {config_name} does not exist. So skip it.\")\n",
    "        continue\n",
    "    logger.info(f\"{config_name} is being evaluated\")\n",
    "\n",
    "    sr_model = make_model(config).to(DEVICE)\n",
    "    sr_model.load_state_dict(torch.load(weight_path, map_location=DEVICE))\n",
    "    _ = sr_model.eval()\n",
    "\n",
    "    test_dataloader = get_testdataloader(ROOT_DIR, config)\n",
    "    bias = test_dataloader.dataset.vorticity_bias\n",
    "    scale = test_dataloader.dataset.vorticity_scale\n",
    "\n",
    "    maes, maers = AverageMeter(), AverageMeter()\n",
    "    for n in tqdm(range(n_loops)):\n",
    "        random.seed(n)\n",
    "        np.random.seed(n)\n",
    "        for lr, obs, gt in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                pred = sr_model(lr.to(DEVICE), obs.to(DEVICE)).detach()\n",
    "                pred = pred * scale + bias\n",
    "                gt = gt * scale + bias\n",
    "\n",
    "                diffs = pred - gt.to(DEVICE)\n",
    "                mae = torch.mean(torch.abs(diffs)).item()\n",
    "                maes.update(mae, n=lr.shape[0])  # n == batch size\n",
    "\n",
    "                # mean over channel, y, x\n",
    "                tmp1 = torch.mean(torch.abs(diffs), dim=(-3, -2, -1))\n",
    "                tmp2 = torch.mean(torch.abs(gt.to(DEVICE)), dim=(-3, -2, -1))\n",
    "                tmp3 = tmp1 / tmp2\n",
    "                # mean over batch, time\n",
    "                maer = torch.mean(tmp3).item()\n",
    "                maers.update(maer, n=lr.shape[0])  # n == batch size\n",
    "\n",
    "            logger.debug(f\"n = {n}, mae = {mae:.10f}\")\n",
    "\n",
    "        df_results.loc[config_name, f\"MAE_n{n+1:02}\"] = maes.avg\n",
    "        df_results.loc[config_name, f\"MAER_n{n+1:02}\"] = maers.avg\n",
    "\n",
    "    del test_dataloader, sr_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    df_results.to_csv(csv_result, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd101c42-79b5-4592-8260-1aa339f5445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name in tqdm(CONFIGS.keys(), total=len(CONFIGS)):\n",
    "    try:\n",
    "        config = CONFIGS[config_name][\"config\"]\n",
    "\n",
    "        df_results.loc[config_name, \"UseObs\"] = config[\"data\"][\"use_observation\"]\n",
    "        df_results.loc[config_name, \"ObsGridInterval\"] = config[\"data\"][\n",
    "            \"obs_grid_interval\"\n",
    "        ]\n",
    "        df_results.loc[config_name, \"ObsGridRatio\"] = (\n",
    "            OBS_GRID_RATIO[config[\"data\"][\"obs_grid_interval\"]] * 100\n",
    "        )\n",
    "        df_results.loc[config_name, \"ObsNoiseStd\"] = config[\"data\"][\"obs_noise_std\"]\n",
    "\n",
    "        df_results.loc[config_name, \"LrTimeInterval\"] = config[\"data\"][\n",
    "            \"lr_time_interval\"\n",
    "        ]\n",
    "        df_results.loc[config_name, \"UseSkipConn\"] = config[\"model\"][\n",
    "            \"use_global_skip_connection\"\n",
    "        ]\n",
    "        df_results.loc[config_name, \"UseMixup\"] = config[\"data\"][\"use_mixup\"]\n",
    "        df_results.loc[config_name, \"alpha\"] = config[\"data\"][\"beta_dist_alpha\"]\n",
    "        df_results.loc[config_name, \"beta\"] = config[\"data\"][\"beta_dist_beta\"]\n",
    "        df_results.loc[config_name, \"UseLrForecast\"] = config[\"data\"].get(\n",
    "            \"use_lr_forecast\", True\n",
    "        )\n",
    "        df_results.loc[config_name, \"Seed\"] = config[\"train\"][\"seed\"]\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c438d6-828f-4b23-a7f2-d0da7ee9f690",
   "metadata": {},
   "source": [
    "# Anlyze errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c7ad1-264b-48ea-b987-48b3f97b6070",
   "metadata": {},
   "source": [
    "## Convergence check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994cfce-7a36-457d-9c57-818830887e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "n_loops = 100\n",
    "\n",
    "for config_name, items in df_results.iterrows():\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    xs, ys = [], []\n",
    "    for n in range(n_loops):\n",
    "        xs.append(n + 1)\n",
    "        ys.append(items[f\"MAE_n{n+1:02}\"])\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    ys = ys / np.mean(ys) * 100\n",
    "\n",
    "    ax.plot(xs, ys, \"o-\")\n",
    "    ax.set_xlabel(\"loop count\")\n",
    "    ax.set_ylabel(\"MAE variation [%]\")\n",
    "    ax.set_title(config_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cfe113-49c2-4609-a45b-2b031775321b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Compoare with/without observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f827b-f090-4b5e-b096-4af3ce9b4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results[df_results[\"UseLrForecast\"] == True].sort_values(\"ObsGridRatio\")\n",
    "ycol = \"MAE_n100\"\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "data = df[(df[\"UseMixup\"] == False) & (df[\"UseObs\"] == True)]\n",
    "\n",
    "data = data.groupby(\"ObsGridRatio\")[ycol].agg(func=[\"mean\", \"count\", \"min\", \"max\"])\n",
    "ys = data[\"mean\"]\n",
    "errs = np.array([ys - data[\"min\"], data[\"max\"] - ys])\n",
    "assert len(ys) == 5 and set(data[\"count\"]) == {5}\n",
    "\n",
    "ax.errorbar(data.index, ys, yerr=errs, fmt=\"o-\", label=\"No Mixup (with obs)\", capsize=5)\n",
    "\n",
    "\n",
    "data = df[(df[\"UseMixup\"] == False) & (df[\"UseObs\"] == False) & (df[\"beta\"] == 2)]\n",
    "\n",
    "data = data.groupby(\"ObsGridRatio\")[ycol].agg(func=[\"mean\", \"count\", \"min\", \"max\"])\n",
    "ys = data[\"mean\"]\n",
    "errs = np.array([ys - data[\"min\"], data[\"max\"] - ys])\n",
    "assert len(ys) == 1 and set(data[\"count\"]) == {5}\n",
    "\n",
    "ax.axhline(ys[0], color=\"k\", ls=\"--\", label=\"No Mixup (without obs)\")\n",
    "\n",
    "\n",
    "data = df[(df[\"UseMixup\"] == True) & (df[\"UseObs\"] == True) & (df[\"beta\"] == 2)]\n",
    "\n",
    "data = data.groupby(\"ObsGridRatio\")[ycol].agg(func=[\"mean\", \"count\", \"min\", \"max\"])\n",
    "ys = data[\"mean\"]\n",
    "errs = np.array([ys - data[\"min\"], data[\"max\"] - ys])\n",
    "assert len(ys) == 5 and set(data[\"count\"]) == {5}\n",
    "\n",
    "ax.errorbar(\n",
    "    data.index, ys, yerr=errs, fmt=\"o-\", label=\"Use Mixup (with obs)\", capsize=5\n",
    ")\n",
    "\n",
    "lg = ax.legend(\n",
    "    bbox_to_anchor=(1.05, 1.0),\n",
    "    loc=\"upper left\",\n",
    "    ncol=1,\n",
    "    fontsize=16,\n",
    "    framealpha=1,\n",
    "    edgecolor=\"k\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Observation point ratio [%]\")\n",
    "ax.set_ylabel(\"MAE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86350c7a-9114-453c-8d43-b374a1bab24c",
   "metadata": {},
   "source": [
    "# Merge SRDA scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb7227-6b21-4806-8ab1-a48296a2b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name in tqdm(CONFIGS.keys(), total=len(CONFIGS)):\n",
    "    csv_file = f\"{CSV_DATA_DIR}/hr_err_time_series_{config_name}_with_mae_ratio.csv\"\n",
    "    if not os.path.exists(csv_file):\n",
    "        logger.error(f\"{csv_file} does not exist!\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    df_results.loc[config_name, \"AveErrSR\"] = df[\"ErrSR\"].mean()\n",
    "    df_results.loc[config_name, \"MaxErrSR\"] = df[\"ErrSR\"].max()\n",
    "    df_results.loc[config_name, \"MinErrSR\"] = df[\"ErrSR\"].min()\n",
    "    df_results.loc[config_name, \"StdErrSR\"] = df[\"ErrSR\"].std()\n",
    "    df_results.loc[config_name, \"Max-MinErrSR\"] = (\n",
    "        df_results.loc[config_name, \"MaxErrSR\"]\n",
    "        - df_results.loc[config_name, \"MinErrSR\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623025c-daef-4aef-9034-ceb87cf825cb",
   "metadata": {},
   "source": [
    "## Compare errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9105c-6594-48d8-bc03-2c0b687bf931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results[df_results[\"UseLrForecast\"] == True].sort_values(\"ObsGridRatio\")\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=[13, 4], sharex=True, sharey=True)\n",
    "\n",
    "for ax, ycol in zip(axes, [\"MAE_n100\", \"AveErrSR\"]):\n",
    "    data = df[(df[\"UseMixup\"] == False) & (df[\"UseObs\"] == True)]\n",
    "    data = data.groupby(\"ObsGridRatio\")[ycol].agg(func=[\"mean\", \"count\", \"min\", \"max\"])\n",
    "    ys = data[\"mean\"]\n",
    "    errs = np.array([ys - data[\"min\"], data[\"max\"] - ys])\n",
    "    assert len(ys) == 5 and set(data[\"count\"]) == {5}\n",
    "    ax.errorbar(data.index, ys, yerr=errs, fmt=\"o--\", label=\"No Mixup\", capsize=5)\n",
    "\n",
    "    # data = df[(df[\"UseMixup\"] == False) & (df[\"UseObs\"] == False) & (df[\"beta\"] == 2)]\n",
    "    # assert len(data) == 1\n",
    "    # ax.axhline(data[ycol].values[0], color=\"k\", ls=\"--\", label=\"No Mixup (without obs)\")\n",
    "\n",
    "    data = df[(df[\"UseMixup\"] == True) & (df[\"UseObs\"] == True) & (df[\"beta\"] == 2)]\n",
    "    data = data.groupby(\"ObsGridRatio\")[ycol].agg(func=[\"mean\", \"count\", \"min\", \"max\"])\n",
    "    ys = data[\"mean\"]\n",
    "    errs = np.array([ys - data[\"min\"], data[\"max\"] - ys])\n",
    "    assert len(ys) == 5 and set(data[\"count\"]) == {5}\n",
    "    ax.errorbar(data.index, ys, yerr=errs, fmt=\"o-\", label=\"Use Mixup\", capsize=5)\n",
    "\n",
    "    ax.set_ylabel(\"MAE\")\n",
    "    ax.set_xlabel(\"Observation point ratio [%]\")\n",
    "    ax.set_xlim([0.5, 6.5])\n",
    "    ax.set_xticks(np.linspace(0.5, 6.5, 4))\n",
    "    ax.set_ylim(0.15, 1.45)\n",
    "    ax.set_yticks(np.linspace(0.2, 1.4, 7))\n",
    "\n",
    "    if ycol == \"MAE_n100\":\n",
    "        ax.set_title(\"No feedback cycles\")\n",
    "    else:\n",
    "        ax.set_title(\"Repeating feedback cycles\")\n",
    "\n",
    "\n",
    "lg = axes[-1].legend(\n",
    "    bbox_to_anchor=(1.05, 1.0),\n",
    "    loc=\"upper left\",\n",
    "    ncol=1,\n",
    "    fontsize=16,\n",
    "    framealpha=1,\n",
    "    edgecolor=\"k\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e080a44-21d4-46f1-ab69-995f127596aa",
   "metadata": {},
   "source": [
    "# Vorticity snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d132773-16cc-45a5-9a98-286e5c917c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_config_name_muT = \"lt4og12_on1e-01_ep1000_lr1e-04_scT_muT_a02_b02_sd221958\"\n",
    "target_config_name_muF = target_config_name_muT.replace(\"muT\", \"muF\")\n",
    "\n",
    "dict_models = {}\n",
    "dataset = None\n",
    "set_seeds(42, use_deterministic=True)\n",
    "\n",
    "for key, config_name in zip(\n",
    "    [\"use_mixup\", \"no_mixup\"], [target_config_name_muT, target_config_name_muF]\n",
    "):\n",
    "    config_info = CONFIGS[config_name]\n",
    "    config = config_info[\"config\"]\n",
    "    weight_path = config_info[\"weight_path\"]\n",
    "\n",
    "    sr_model = make_model(config).to(DEVICE)\n",
    "    sr_model.load_state_dict(torch.load(weight_path, map_location=DEVICE))\n",
    "    _ = sr_model.eval()\n",
    "\n",
    "    dict_models[key] = sr_model\n",
    "\n",
    "    if key == \"no_mixup\":\n",
    "        if os.path.exists(\"/workspace/all_data\"):\n",
    "            dataset = get_testdataloader(\"/workspace/all_data\", config).dataset\n",
    "        else:\n",
    "            dataset = get_testdataloader(ROOT_DIR, config).dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263d84e-1137-41ca-8e7b-bf00be17f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42, use_deterministic=True)\n",
    "lr, obs, gt = dataset.__getitem__(8)\n",
    "\n",
    "gt = gt[-1, 0].permute(1, 0).numpy()\n",
    "gt = gt * dataset.vorticity_scale + dataset.vorticity_bias\n",
    "dict_data = {\"HR\": gt}\n",
    "\n",
    "for key, model in dict_models.items():\n",
    "    pred = model(lr[None, ...].to(DEVICE), obs[None, ...].to(DEVICE))\n",
    "    pred = pred.squeeze().detach().cpu()\n",
    "    pred = pred * dataset.vorticity_scale + dataset.vorticity_bias\n",
    "    dict_data[key] = pred[-1].permute(1, 0).numpy()\n",
    "\n",
    "obs = torch.where(obs == dataset.missing_value, torch.full_like(obs, torch.nan), obs)\n",
    "obs = obs[-1, 0] * dataset.vorticity_scale + dataset.vorticity_bias\n",
    "obs = obs.numpy()\n",
    "\n",
    "plot(\n",
    "    dict_data,\n",
    "    t=0,\n",
    "    obs=obs,\n",
    "    figsize=[12, 4.0],\n",
    "    ttl_header=\"\",\n",
    "    fig_file_name=\"\",\n",
    "    write_out=False,\n",
    "    use_hr_space=True,\n",
    "    vmin_omega=-10,\n",
    "    vmax_omega=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d435992-ebbf-4cd1-9a5d-cf1c17fd10e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1ad94-af17-4af6-8ff1-3a9e21c337e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
